{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MATRIX FACTORIZATION TECHNIQUES FOR RECOMMENDER SYSTEMS.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPf3MMgV/yNCJDr39mqSr51",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MaximilianoRamirezN/lecturasIIC3633-2021/blob/main/papers/Semana2/MATRIX_FACTORIZATION_TECHNIQUES_FOR_RECOMMENDER_SYSTEMS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6u2l2HvZVm3"
      },
      "source": [
        "# MATRIX FACTORIZATION TECHNIQUES FOR RECOMMENDER SYSTEMS\n",
        "\n",
        "Trabajo que contrapone métodos de filtrados colaborativos estándares, como los métodos basados en items o usuarios, con los métodos de factorización matricial y factores latentes tanto en usuarios como en items. Esto último, da la intuición de como es posible representar a los usuarios e items en subespacios, idealmente de menor dimensionalidad, y cómo es posible medir similitud entre usuarios e items, dicha medida es la que determina el rating que un usuario le daría a un item determinado. La forma de hacer más eficiente este enfoque, es representar usuarios e items en una matriz, y a través de distintas técnicas de factorización matricial las cuales presentan elinconveniente de la poca densidad de datos en la matriz, sin embargo, esto es lo que permite lidiar con el **_Cold Start Problem_**, lo que en uno de los beneficios de los métodos de factorización matricial.\n",
        "\n",
        "La forma de entrenar estos métodos es minimizar el error cuadrático que comete la medida de similaridad $q_i^{t}p_u$ al intentar estimar el rating que el el usuario $u$ le daría al item $i$ ($r_{ui}$), añadiendo una penalización que considera los factores latentes del usuario y el item dónde el algoritmo utilizado puede ser **Stochastic gradient descent** o **Alternating least squares**. Naturalmente hay variantes que consideran sesgos de los usuarios e items, permitiendo al modelo captar cambios en las tendencias de gustos que van cambiando temporalmente.\n",
        "\n",
        "Dentro de las preguntas naturales que surgen sobre este trabajo es, ¿Qué ocurre si penalizamos con otra norma?, los autores presentan el método de penalización con norma $\\ell_2$, o conocido en la literatura con _Ridge Regression Penalty_. Por otro lado, podriamos considerar una penalización con norma $\\ell_1$, lo que da origen a la conocida penalización _lasso_. Esta última según los autores en el siguiente [trabajo](https://personal.eur.nl/frasincar/papers/SAC2020a/sac2020a.pdf), presenta dificultades para identificar factores latentes cuando el problema tiene alta dimensionalidad, es por esto que estudian el uso de **_Elastic net_**, el cúal es una penalización que combina linealmente las normas $\\ell_1$ y $\\ell_2$, obteniendo mejoras en la presición de las recomendaciones considerando _MAE_ como la pérdida utilizada en el conjunto de datos de _MovieLens_.\n",
        "\n",
        "Finalmente, las conclusiones extraídas de este trabajo es que los métodos de factorización permiten lidiar con problemas de los sitemas colaborativos como el _Cold Start_, y realizar recomendaciones personalizadas más robustas y con costos computacionales menores a los métodos como _User-KNN_ o _Item-KNN_."
      ]
    }
  ]
}